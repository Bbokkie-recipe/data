{
  "copyright_text": null,
  "description": "Transformer e Meccanismi di Attenzione: modelli che stanno rivoluzionando l'Intelligenza Artificiale - PyCon Italia 2022\n\nAnalizziamo le caratteristiche che permettono alle architetture di reti neurali artificiali basate sui Transformer di diventare i nuovi modelli SotA in tutti i domini applicativi. Descriveremo dalle tecniche seq-2-seq ai meccanismi di attenzione, dai vettori posizionali al Perceiver-IO.\nLe architetture di rete neurale artificiale basate sui Transformer stanno rivoluzionando il mondo del Deep Learning, permettendo ai relativi nuovi modelli di surclassare tutte le precedenti soluzioni allo stato dell'arte.\nOltre che in ambito Natural Language Processing, dove i Transformer sono nati e sono stati fatti evolvere, oggi possiamo sfruttare lo stesso approccio in qualsiasi altro ambito, come in Computer Vision o per l'analisi di segnali industriali.\nLo scopo del talk \u00e8 di spiegare in maniera comprensibile il funzionamento dei principali componenti di queste architetture per scoprirne i segreti e capirne il funzionamento.\nSlide: \n\n\nSpeaker: Vincenzo Maritati",
  "duration": 1877,
  "language": "ita",
  "recorded": "2022-06-03",
  "speakers": [
    "Vincenzo Maritati"
  ],
  "tags": [
    "deep learning",
    "machine learning"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/P0pqyK5UO2Y/maxresdefault.jpg",
  "title": "Transformer e Meccanismi di Attenzione: modelli che rivoluzionano l'AI",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=P0pqyK5UO2Y"
    }
  ]
}