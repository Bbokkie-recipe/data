{
    "copyright_text": null,
    "description": "I'm going to summarize the outline of Model Serving, one of the fields of MLOps. I'll explain what to do in the field of Model Serving through a framework called BentoML.\n\nThis session covers the following two major topics.\n\nModel Serving Framework: BentoML, torchserve, tenrsorflowserving, triton-inference-server\nModel Serving Platform: kserve, yatai, sagemaker (deploy part)\n\nI'll mainly show examples through BentoML and compare other frameworks.\n\nKim Seong-ryeol\nI'm working on Serving in the Naver Biz CIC advertising recommendation section.",
    "duration": 2473,
    "language": "kor",
    "recorded": "2023-08-12",
    "related_urls": [
        {
            "label": "MLOps Model Serving Architecture with BentoML",
            "url": "https://2023.pycon.kr/session"
        }
    ],
    "speakers": [
        "Kim Seong-ryeol"
    ],
    "tags": [],
    "thumbnail_url": "https://i.ytimg.com/vi/2AjVDjR0jLM/default.jpg",
    "title": "MLOps Model Serving Architecture with BentoML",
    "videos": [
        {
            "type": "Youtube",
            "url": "https://www.youtube.com/watch?v=2AjVDjR0jLM"
        }
    ]
}